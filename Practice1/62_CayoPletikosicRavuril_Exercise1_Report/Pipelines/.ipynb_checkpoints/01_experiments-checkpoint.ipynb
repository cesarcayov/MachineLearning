{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701911f6-a52c-48ca-af6a-235135c2ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#   EXERCISE 1: CLASSIFIER PIPELINES (SVM, RF, NN)\n",
    "# ================================================================\n",
    "\n",
    "# === 1. Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef9bde0-77e1-4e09-a493-c569c5b84ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# === 2. Load all cleaned datasets ===\n",
    "datasets = {\n",
    "    \"dataset1\": pd.read_csv(\"dataset1_clean.csv\"),\n",
    "    \"dataset2\": pd.read_csv(\"dataset2_clean.csv\"),\n",
    "    \"dataset3\": pd.read_csv(\"dataset3_clean.csv\"),\n",
    "    \"dataset4\": pd.read_csv(\"dataset4_clean.csv\")\n",
    "}\n",
    "\n",
    "print(\"✅ All datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce1b163-7245-4d7f-b90d-34efe05cf2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipelines created for SVM, RF, NN\n"
     ]
    }
   ],
   "source": [
    "# === 3. Define classifier pipelines ===\n",
    "models = {\n",
    "    \"SVM_rbf\": make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")),\n",
    "    \"RandomForest\": make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    \"NeuralNet\": make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42))\n",
    "}\n",
    "\n",
    "print(\"✅ Pipelines created for SVM, RF, NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838c8722-f80f-462f-820c-9ebe6558950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Define evaluation functions ===\n",
    "def evaluate_holdout(model, X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    return {\"Accuracy\": acc, \"F1_macro\": f1, \"Train_time_s\": train_time, \"Infer_time_s\": infer_time}\n",
    "\n",
    "def evaluate_cv(model, X, y, cv=5):\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    acc = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\", n_jobs=-1)\n",
    "    f1 = cross_val_score(model, X, y, cv=kfold, scoring=\"f1_macro\", n_jobs=-1)\n",
    "    return {\"CV_Accuracy_mean\": acc.mean(), \"CV_Accuracy_std\": acc.std(),\n",
    "            \"CV_F1_mean\": f1.mean(), \"CV_F1_std\": f1.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e19441-3364-47c0-92ae-0b80b960ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: dataset1 ===\n",
      "→ Running SVM_rbf...\n",
      "→ Running RandomForest...\n",
      "→ Running NeuralNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: dataset2 ===\n",
      "→ Running SVM_rbf...\n",
      "→ Running RandomForest...\n",
      "→ Running NeuralNet...\n",
      "\n",
      "=== Dataset: dataset3 ===\n",
      "→ Running SVM_rbf...\n",
      "→ Running RandomForest...\n",
      "→ Running NeuralNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: dataset4 ===\n",
      "→ Running SVM_rbf...\n",
      "→ Running RandomForest...\n",
      "→ Running NeuralNet...\n"
     ]
    }
   ],
   "source": [
    "# === 5. Run experiments ===\n",
    "results = []\n",
    "\n",
    "for dname, df in datasets.items():\n",
    "    print(f\"\\n=== Dataset: {dname} ===\")\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    # Handle non-numeric targets if any\n",
    "    if not np.issubdtype(y.dtype, np.number):\n",
    "        y = pd.factorize(y)[0]\n",
    "\n",
    "    for mname, model in models.items():\n",
    "        print(f\"→ Running {mname}...\")\n",
    "        try:\n",
    "            holdout_metrics = evaluate_holdout(model, X, y)\n",
    "            cv_metrics = evaluate_cv(model, X, y)\n",
    "            results.append({\n",
    "                \"Dataset\": dname,\n",
    "                \"Model\": mname,\n",
    "                **holdout_metrics,\n",
    "                **cv_metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {dname} - {mname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c71c83-ad50-4d5c-b081-a1ea6edc7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All experiments complete! Results saved to results_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Train_time_s</th>\n",
       "      <th>Infer_time_s</th>\n",
       "      <th>CV_Accuracy_mean</th>\n",
       "      <th>CV_Accuracy_std</th>\n",
       "      <th>CV_F1_mean</th>\n",
       "      <th>CV_F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset1</td>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.681450</td>\n",
       "      <td>0.150221</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>0.686249</td>\n",
       "      <td>0.029627</td>\n",
       "      <td>0.670953</td>\n",
       "      <td>0.028535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.896240</td>\n",
       "      <td>0.313368</td>\n",
       "      <td>0.021006</td>\n",
       "      <td>0.889364</td>\n",
       "      <td>0.028039</td>\n",
       "      <td>0.889636</td>\n",
       "      <td>0.027464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset1</td>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.728480</td>\n",
       "      <td>1.310231</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.728019</td>\n",
       "      <td>0.014769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset2</td>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>110.288555</td>\n",
       "      <td>17.600029</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>30.925761</td>\n",
       "      <td>0.375053</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset2</td>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>34.317478</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset3</td>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.883190</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.914328</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>0.913713</td>\n",
       "      <td>0.020609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401967</td>\n",
       "      <td>0.026652</td>\n",
       "      <td>0.993077</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.993075</td>\n",
       "      <td>0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset3</td>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968211</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset4</td>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>73.593191</td>\n",
       "      <td>14.177604</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.669935</td>\n",
       "      <td>0.005039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.811667</td>\n",
       "      <td>0.671410</td>\n",
       "      <td>16.271092</td>\n",
       "      <td>0.225560</td>\n",
       "      <td>0.816200</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.680381</td>\n",
       "      <td>0.004885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset4</td>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>0.809667</td>\n",
       "      <td>0.676214</td>\n",
       "      <td>45.744973</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.676175</td>\n",
       "      <td>0.009324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset         Model  Accuracy  F1_macro  Train_time_s  Infer_time_s  \\\n",
       "0   dataset1       SVM_rbf  0.701299  0.681450      0.150221      0.060483   \n",
       "1   dataset1  RandomForest  0.896104  0.896240      0.313368      0.021006   \n",
       "2   dataset1     NeuralNet  0.733766  0.728480      1.310231      0.003317   \n",
       "3   dataset2       SVM_rbf  0.999724  0.999718    110.288555     17.600029   \n",
       "4   dataset2  RandomForest  0.999979  0.999978     30.925761      0.375053   \n",
       "5   dataset2     NeuralNet  0.999958  0.999957     34.317478      0.102950   \n",
       "6   dataset3       SVM_rbf  0.885057  0.883190      0.012665      0.012983   \n",
       "7   dataset3  RandomForest  1.000000  1.000000      0.401967      0.026652   \n",
       "8   dataset3     NeuralNet  1.000000  1.000000      0.968211      0.002805   \n",
       "9   dataset4       SVM_rbf  0.816000  0.669065     73.593191     14.177604   \n",
       "10  dataset4  RandomForest  0.811667  0.671410     16.271092      0.225560   \n",
       "11  dataset4     NeuralNet  0.809667  0.676214     45.744973      0.006901   \n",
       "\n",
       "    CV_Accuracy_mean  CV_Accuracy_std  CV_F1_mean  CV_F1_std  \n",
       "0           0.686249         0.029627    0.670953   0.028535  \n",
       "1           0.889364         0.028039    0.889636   0.027464  \n",
       "2           0.731771         0.013212    0.728019   0.014769  \n",
       "3           0.999763         0.000036    0.999757   0.000037  \n",
       "4           0.999996         0.000008    0.999996   0.000009  \n",
       "5           0.999945         0.000022    0.999944   0.000022  \n",
       "6           0.914328         0.020334    0.913713   0.020609  \n",
       "7           0.993077         0.005653    0.993075   0.005654  \n",
       "8           1.000000         0.000000    1.000000   0.000000  \n",
       "9           0.818900         0.003928    0.669935   0.005039  \n",
       "10          0.816200         0.002889    0.680381   0.004885  \n",
       "11          0.813800         0.004155    0.676175   0.009324  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 6. Save & show results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results_summary.csv\", index=False)\n",
    "print(\"\\n✅ All experiments complete! Results saved to results_summary.csv\")\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
