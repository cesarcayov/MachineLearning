{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-11-10T00:16:20.056433Z",
     "end_time": "2025-11-10T00:16:20.149087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (12, 10)\n",
      "    Dataset         Model  Accuracy  F1_macro  Train_time_s  Infer_time_s  \\\n",
      "0  dataset1       SVM_rbf  0.701299  0.681450      0.150221      0.060483   \n",
      "1  dataset1  RandomForest  0.896104  0.896240      0.313368      0.021006   \n",
      "2  dataset1     NeuralNet  0.733766  0.728480      1.310231      0.003317   \n",
      "3  dataset2       SVM_rbf  0.999724  0.999718    110.288555     17.600029   \n",
      "4  dataset2  RandomForest  0.999979  0.999978     30.925761      0.375053   \n",
      "\n",
      "   CV_Accuracy_mean  CV_Accuracy_std  CV_F1_mean  CV_F1_std  \n",
      "0          0.686249         0.029627    0.670953   0.028535  \n",
      "1          0.889364         0.028039    0.889636   0.027464  \n",
      "2          0.731771         0.013212    0.728019   0.014769  \n",
      "3          0.999763         0.000036    0.999757   0.000037  \n",
      "4          0.999996         0.000008    0.999996   0.000009  \n",
      "✅ Tables and summaries exported to: /Users/vp/PycharmProjects/MachineLearning/Practice1/62_CayoPletikosicRavuril_Exercise1_Report/Pipelines/.ipynb_checkpoints/cross_check_outputs\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Cross-Dataset Summary"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "          Model  Accuracy  F1_macro  Train_time_s  Infer_time_s  \\\n1  RandomForest     0.927     0.892        11.978         0.162   \n0     NeuralNet     0.886     0.851        20.585         0.029   \n2       SVM_rbf     0.851     0.808        46.011         7.963   \n\n   CV_Accuracy_mean  CV_Accuracy_std  CV_F1_mean  CV_F1_std  Wins_Accuracy  \\\n1             0.925            0.009       0.891      0.010              3   \n0             0.886            0.004       0.851      0.006              0   \n2             0.855            0.013       0.814      0.014              1   \n\n   Wins_F1_macro  \n1              3  \n0              1  \n2              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>F1_macro</th>\n      <th>Train_time_s</th>\n      <th>Infer_time_s</th>\n      <th>CV_Accuracy_mean</th>\n      <th>CV_Accuracy_std</th>\n      <th>CV_F1_mean</th>\n      <th>CV_F1_std</th>\n      <th>Wins_Accuracy</th>\n      <th>Wins_F1_macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>0.927</td>\n      <td>0.892</td>\n      <td>11.978</td>\n      <td>0.162</td>\n      <td>0.925</td>\n      <td>0.009</td>\n      <td>0.891</td>\n      <td>0.010</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NeuralNet</td>\n      <td>0.886</td>\n      <td>0.851</td>\n      <td>20.585</td>\n      <td>0.029</td>\n      <td>0.886</td>\n      <td>0.004</td>\n      <td>0.851</td>\n      <td>0.006</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM_rbf</td>\n      <td>0.851</td>\n      <td>0.808</td>\n      <td>46.011</td>\n      <td>7.963</td>\n      <td>0.855</td>\n      <td>0.013</td>\n      <td>0.814</td>\n      <td>0.014</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Accuracy per Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Model     NeuralNet  RandomForest  SVM_rbf\nDataset                                   \ndataset1      0.734         0.896    0.701\ndataset2      1.000         1.000    1.000\ndataset3      1.000         1.000    0.885\ndataset4      0.810         0.812    0.816",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Model</th>\n      <th>NeuralNet</th>\n      <th>RandomForest</th>\n      <th>SVM_rbf</th>\n    </tr>\n    <tr>\n      <th>Dataset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dataset1</th>\n      <td>0.734</td>\n      <td>0.896</td>\n      <td>0.701</td>\n    </tr>\n    <tr>\n      <th>dataset2</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>dataset3</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.885</td>\n    </tr>\n    <tr>\n      <th>dataset4</th>\n      <td>0.810</td>\n      <td>0.812</td>\n      <td>0.816</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### F1 per Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Model     NeuralNet  RandomForest  SVM_rbf\nDataset                                   \ndataset1      0.728         0.896    0.681\ndataset2      1.000         1.000    1.000\ndataset3      1.000         1.000    0.883\ndataset4      0.676         0.671    0.669",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Model</th>\n      <th>NeuralNet</th>\n      <th>RandomForest</th>\n      <th>SVM_rbf</th>\n    </tr>\n    <tr>\n      <th>Dataset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dataset1</th>\n      <td>0.728</td>\n      <td>0.896</td>\n      <td>0.681</td>\n    </tr>\n    <tr>\n      <th>dataset2</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>dataset3</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.883</td>\n    </tr>\n    <tr>\n      <th>dataset4</th>\n      <td>0.676</td>\n      <td>0.671</td>\n      <td>0.669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "# 1) Read the results\n",
    "# =====================================================\n",
    "# Make sure the file is in your working directory or adjust the path\n",
    "df = pd.read_csv(\"../results_summary.csv\")\n",
    "\n",
    "# Inspect structure\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# =====================================================\n",
    "# 2) Compute summary statistics per Model (averaged over datasets)\n",
    "# =====================================================\n",
    "summary_cols = [\n",
    "    \"Accuracy\", \"F1_macro\", \"Train_time_s\", \"Infer_time_s\",\n",
    "    \"CV_Accuracy_mean\", \"CV_Accuracy_std\", \"CV_F1_mean\", \"CV_F1_std\"\n",
    "]\n",
    "\n",
    "summary = (\n",
    "    df.groupby(\"Model\", as_index=False)[summary_cols]\n",
    "      .mean(numeric_only=True)\n",
    "      .sort_values(\"Accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 3) Count how many datasets each model \"won\" (highest Accuracy / F1)\n",
    "# =====================================================\n",
    "def count_wins(metric):\n",
    "    winners = df.loc[df.groupby(\"Dataset\")[metric].idxmax()]\n",
    "    return winners[\"Model\"].value_counts().rename(f\"Wins_{metric}\")\n",
    "\n",
    "win_acc = count_wins(\"Accuracy\")\n",
    "win_f1 = count_wins(\"F1_macro\")\n",
    "\n",
    "summary = summary.merge(win_acc, left_on=\"Model\", right_index=True, how=\"left\")\n",
    "summary = summary.merge(win_f1, left_on=\"Model\", right_index=True, how=\"left\")\n",
    "summary[[\"Wins_Accuracy\", \"Wins_F1_macro\"]] = summary[[\"Wins_Accuracy\", \"Wins_F1_macro\"]].fillna(0).astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# 4) Create per-dataset pivot tables\n",
    "# =====================================================\n",
    "acc_pivot = df.pivot(index=\"Dataset\", columns=\"Model\", values=\"Accuracy\")\n",
    "f1_pivot = df.pivot(index=\"Dataset\", columns=\"Model\", values=\"F1_macro\")\n",
    "cv_acc_pivot = df.pivot(index=\"Dataset\", columns=\"Model\", values=\"CV_Accuracy_mean\")\n",
    "cv_f1_pivot = df.pivot(index=\"Dataset\", columns=\"Model\", values=\"CV_F1_mean\")\n",
    "\n",
    "# Round values for readability\n",
    "for d in [summary, acc_pivot, f1_pivot, cv_acc_pivot, cv_f1_pivot]:\n",
    "    d.round(3)\n",
    "\n",
    "# =====================================================\n",
    "# 5) Save outputs (CSV + LaTeX)\n",
    "# =====================================================\n",
    "outdir = Path(\"cross_check_outputs\")\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "summary.to_csv(outdir / \"cross_dataset_summary.csv\", index=False)\n",
    "acc_pivot.to_csv(outdir / \"per_dataset_accuracy.csv\")\n",
    "f1_pivot.to_csv(outdir / \"per_dataset_f1.csv\")\n",
    "cv_acc_pivot.to_csv(outdir / \"per_dataset_cv_accuracy.csv\")\n",
    "cv_f1_pivot.to_csv(outdir / \"per_dataset_cv_f1.csv\")\n",
    "\n",
    "# Helper to make clean LaTeX tables\n",
    "def to_latex(df_, caption, label, index=True):\n",
    "    return df_.to_latex(escape=True, index=index, caption=caption, label=label, float_format=\"%.3f\")\n",
    "\n",
    "latex_summary = to_latex(summary.set_index(\"Model\"),\n",
    "                         \"Average performance across datasets (higher is better).\",\n",
    "                         \"tab:cross_dataset_summary\")\n",
    "\n",
    "latex_acc = to_latex(acc_pivot,\n",
    "                     \"Per-dataset Accuracy by model.\",\n",
    "                     \"tab:per_dataset_accuracy\")\n",
    "\n",
    "latex_f1 = to_latex(f1_pivot,\n",
    "                    \"Per-dataset F1-macro by model.\",\n",
    "                    \"tab:per_dataset_f1\")\n",
    "\n",
    "latex_cv_acc = to_latex(cv_acc_pivot,\n",
    "                        \"Per-dataset CV Accuracy mean by model.\",\n",
    "                        \"tab:per_dataset_cv_accuracy\")\n",
    "\n",
    "latex_cv_f1 = to_latex(cv_f1_pivot,\n",
    "                       \"Per-dataset CV F1 mean by model.\",\n",
    "                       \"tab:per_dataset_cv_f1\")\n",
    "\n",
    "# Save all LaTeX tables to one .tex file\n",
    "with open(outdir / \"tables.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"% Cross-dataset summary\\n\")\n",
    "    f.write(latex_summary + \"\\n\\n\")\n",
    "    f.write(\"% Per-dataset Accuracy\\n\")\n",
    "    f.write(latex_acc + \"\\n\\n\")\n",
    "    f.write(\"% Per-dataset F1_macro\\n\")\n",
    "    f.write(latex_f1 + \"\\n\\n\")\n",
    "    f.write(\"% Per-dataset CV Accuracy\\n\")\n",
    "    f.write(latex_cv_acc + \"\\n\\n\")\n",
    "    f.write(\"% Per-dataset CV F1\\n\")\n",
    "    f.write(latex_cv_f1 + \"\\n\\n\")\n",
    "\n",
    "print(\"✅ Tables and summaries exported to:\", outdir.resolve())\n",
    "\n",
    "# =====================================================\n",
    "# 6) (Optional) Display in notebook\n",
    "# =====================================================\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(\"### Cross-Dataset Summary\"))\n",
    "    display(summary.round(3))\n",
    "    display(Markdown(\"### Accuracy per Dataset\"))\n",
    "    display(acc_pivot.round(3))\n",
    "    display(Markdown(\"### F1 per Dataset\"))\n",
    "    display(f1_pivot.round(3))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
